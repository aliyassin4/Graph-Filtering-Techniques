{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import os, sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "from Backbones.high_salience_skeleton import high_salience_skeleton as hss\n",
    "from Backbones.doubly_stochastic import read\n",
    "from Backbones.marginal_likelihood_filter import MLF\n",
    "from Backbones import disparity_filter as disf\n",
    "from Backbones.noise_corrected import noise_corrected as nc\n",
    "from Backbones.lans_backbone import lans\n",
    "\n",
    "\n",
    "from Utils.code_utils import convert_label_to_integers, relabel_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Netowrk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the network name and dataset path\n",
    "network = 'airports'\n",
    "path = '../Results/All Backbones/'\n",
    "#path = '../Datasets/'\n",
    "\n",
    "# read edge list from csv file\n",
    "edge_list = pd.read_csv( path+ network + '.csv')\n",
    "edge_list.weight = edge_list.weight.astype(int)\n",
    "\n",
    "# read edge list from csv file for the doubly stochastic filter, noice corrected and the high salience skeleton\n",
    "table, nnodes, nnedges = read(path + network + '.csv', \"weight\", sep=',', consider_self_loops=False, triangular_input = True, undirected=True) \n",
    "table.weight = table.weight.astype(int)  \n",
    "\n",
    "# create graph from the edge list\n",
    "G = nx.from_pandas_edgelist(edge_list, edge_attr='weight', create_using=nx.Graph())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do\n",
    "# later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add alpha values to the original graph\n",
    "for u,v, weight in G.edges(data='weight'):\n",
    "    G[u][v]['global_score'] = weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disparity Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the disparity filter algorithm\n",
    "backbone = disf.disparity_filter(G)\n",
    "\n",
    "# add alpha values to the original graph\n",
    "for u,v, alpha in backbone.edges(data='alpha'):\n",
    "    G[u][v]['df_alpha'] = alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd29e3",
   "metadata": {},
   "source": [
    "## The High Saleince Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the high salience skeleton algorithm\n",
    "# hss_backbone = hss(table, return_self_loops=False, undirected=True)\n",
    "    \n",
    "# # sort score values of the edges\n",
    "# hss_backbone = hss_backbone.rename(columns={'score': 'threshold'})\n",
    "\n",
    "# # add score values to the original graph\n",
    "# for u, v in G.edges():\n",
    "#     G[u][v]['hss_score'] = hss_backbone[((hss_backbone['source'] == u) & (hss_backbone['target'] == v)) | ((hss_backbone['source'] == v) & (hss_backbone['target'] == u))]['threshold'].iloc[-1]\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10f031c",
   "metadata": {},
   "source": [
    "# Marginal Likelihood Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformer to the edgelist\n",
    "mlf = MLF(directed=False)\n",
    "mlf_backbone = mlf.fit_transform(edge_list)\n",
    "\n",
    "#sort score values of the edges\n",
    "mlf_backbone = mlf_backbone.rename(columns={'significance': 'threshold'})\n",
    "\n",
    "# add score values to the original graph\n",
    "for u, v in G.edges():\n",
    "    G[u][v]['mlf_score'] = mlf_backbone[((mlf_backbone['source'] == u) & (mlf_backbone['target'] == v)) | ((mlf_backbone['source'] == v) & (mlf_backbone['target'] == u))]['threshold'].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d8de2",
   "metadata": {},
   "source": [
    "# Noise Corrected Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a4c100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the noise corrected filter\n",
    "#nc_backbone = nc(table, undirected = True, return_self_loops = False, calculate_p_value=True)\n",
    "nc_backbone = nc(table, undirected = True, return_self_loops = False, calculate_p_value=True)\n",
    "#nc_backbone['threshold'] = nc_backbone[\"score\"] - (1 * nc_backbone[\"sdev_cij\"])\n",
    "nc_backbone['threshold'] = 1 - nc_backbone[\"score\"]\n",
    "\n",
    "# add score values to the original graph\n",
    "for u, v in G.edges():\n",
    "    G[u][v]['nc_alpha'] = nc_backbone[((nc_backbone['source'] == u) & (nc_backbone['target'] == v)) | ((nc_backbone['source'] == v) & (nc_backbone['target'] == u))]['threshold'].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680dcd23",
   "metadata": {},
   "source": [
    "## The Polya Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31bc0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read edge list from csv file\n",
    "pf_backbone = pd.read_csv('../Results/Backbones Results/PF/' + network + '.csv')\n",
    "\n",
    "#sort score values of the edges\n",
    "pf_backbone = pf_backbone.rename(columns={'p_values': 'threshold'})\n",
    "\n",
    "\n",
    "# add score values to the original graph\n",
    "for u, v in G.edges():\n",
    "    G[u][v]['pf_alpha'] = pf_backbone[((pf_backbone['source'] == u) & (pf_backbone['target'] == v)) | ((pf_backbone['source'] == v) & (pf_backbone['target'] == u))]['threshold'].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1081e2e",
   "metadata": {},
   "source": [
    "## Gloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "046c5816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read edge list from csv file\n",
    "gloss_backbone = pd.read_csv('../Results/Backbones Results/GLOSS/' + network + '.csv', names=['source', 'target', 'threshold', 'weight'], sep=' ')\n",
    "\n",
    "# #for lesmis\n",
    "# labels = pd.read_csv('../Datasets/' + network + '_labels.csv', index_col='index')\n",
    "\n",
    "# #relabel using saved labels\n",
    "# labels = labels.T.to_dict('list')\n",
    "# gloss_backbone['source'] = gloss_backbone['source'].replace(labels)\n",
    "# gloss_backbone['target'] = gloss_backbone['target'].replace(labels)\n",
    "\n",
    "\n",
    "# # add score values to the original graph\n",
    "for u, v in G.edges():\n",
    "    G[u][v]['gloss_alpha'] = gloss_backbone[((gloss_backbone['source'] == u) & (gloss_backbone['target'] == v)) | ((gloss_backbone['source'] == v) & (gloss_backbone['target'] == u))]['threshold'].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lans Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lans(G)\n",
    "\n",
    "for u, v in G.edges():\n",
    "    G[u][v]['lans_alpha'] = g[u][v]['p-value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECM Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:absl:Initializing backend 'interpreter'\n",
      "DEBUG:absl:Backend 'interpreter' initialized\n",
      "DEBUG:absl:Initializing backend 'cpu'\n",
      "DEBUG:absl:Backend 'cpu' initialized\n",
      "DEBUG:absl:Initializing backend 'tpu_driver'\n",
      "INFO:absl:Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: \n",
      "DEBUG:absl:Initializing backend 'gpu'\n",
      "INFO:absl:Unable to initialize backend 'gpu': NOT_FOUND: Could not find registered platform with name: \"cuda\". Available platform names are: Host Interpreter\n",
      "DEBUG:absl:Initializing backend 'tpu'\n",
      "INFO:absl:Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "DEBUG:absl:Finished tracing + transforming transform_parameters_inv for jit in 0.0030879974365234375 sec\n",
      "DEBUG:absl:Compiling transform_parameters_inv (140668530470496 for args (ShapedArray(float32[5468]),).\n",
      "DEBUG:absl:Finished XLA compilation of transform_parameters_inv in 0.24920392036437988 sec\n",
      "DEBUG:absl:Finished tracing + transforming neg_log_likelihood for jit in 0.011074066162109375 sec\n",
      "DEBUG:absl:Compiling neg_log_likelihood (140668797478944 for args (ShapedArray(float32[5468]),).\n",
      "DEBUG:absl:Finished XLA compilation of neg_log_likelihood in 0.17145085334777832 sec\n",
      "DEBUG:absl:Finished tracing + transforming neg_log_likelihood for jit in 0.03818488121032715 sec\n",
      "DEBUG:absl:Compiling neg_log_likelihood (140668534814592 for args (ShapedArray(float32[5468]),).\n",
      "DEBUG:absl:Finished XLA compilation of neg_log_likelihood in 0.20849204063415527 sec\n",
      "DEBUG:absl:Finished tracing + transforming <lambda> for jit in 0.05609273910522461 sec\n",
      "DEBUG:absl:Compiling <lambda> (140668792512336 for args (ShapedArray(float32[5468]), ShapedArray(float32[5468])).\n",
      "DEBUG:absl:Finished XLA compilation of <lambda> in 0.41841888427734375 sec\n",
      "DEBUG:absl:Finished tracing + transforming fn for jit in 0.0003688335418701172 sec\n",
      "DEBUG:absl:Compiling fn (140668802480000 for args (ShapedArray(float32[]), ShapedArray(float32[])).\n",
      "DEBUG:absl:Finished XLA compilation of fn in 0.006896018981933594 sec\n",
      "DEBUG:absl:Finished tracing + transforming <lambda> for jit in 0.0003521442413330078 sec\n",
      "DEBUG:absl:Compiling <lambda> (140668797463200 for args (ShapedArray(float32[]), ShapedArray(float32[])).\n",
      "DEBUG:absl:Finished XLA compilation of <lambda> in 0.005994081497192383 sec\n",
      "DEBUG:absl:Finished tracing + transforming prim_fun for jit in 0.00016999244689941406 sec\n",
      "DEBUG:absl:Finished tracing + transforming prim_fun for jit in 0.0001747608184814453 sec\n",
      "DEBUG:absl:Compiling prim_fun (140668797478944 for args (ShapedArray(float32[]), ShapedArray(float32[])).\n",
      "DEBUG:absl:Finished XLA compilation of le in 0.0077016353607177734 sec\n",
      "DEBUG:absl:Finished tracing + transforming true_divide for jit in 0.00032520294189453125 sec\n",
      "DEBUG:absl:Compiling true_divide (140668799843056 for args (ShapedArray(float32[]), ShapedArray(float32[])).\n",
      "DEBUG:absl:Finished XLA compilation of true_divide in 0.006780862808227539 sec\n",
      "DEBUG:absl:Finished tracing + transforming prim_fun for jit in 0.000186920166015625 sec\n",
      "DEBUG:absl:Compiling prim_fun (140668799843056 for args (ShapedArray(float32[], weak_type=True),).\n",
      "DEBUG:absl:Finished XLA compilation of convert_element_type in 0.0068628787994384766 sec\n",
      "DEBUG:absl:Finished tracing + transforming prim_fun for jit in 0.00022411346435546875 sec\n",
      "DEBUG:absl:Compiling prim_fun (140668541589296 for args (ShapedArray(float32[]), ShapedArray(float32[])).\n",
      "DEBUG:absl:Finished XLA compilation of lt in 0.00621485710144043 sec\n",
      "DEBUG:absl:Finished tracing + transforming prim_fun for jit in 0.000225067138671875 sec\n",
      "DEBUG:absl:Compiling prim_fun (140668799823616 for args (ShapedArray(float32[]), ShapedArray(float32[])).\n",
      "DEBUG:absl:Finished XLA compilation of gt in 0.006616830825805664 sec\n",
      "DEBUG:absl:Finished tracing + transforming node_sequence_residuals for jit in 0.018519878387451172 sec\n",
      "DEBUG:absl:Compiling node_sequence_residuals (140668530430592 for args (ShapedArray(float32[5468]),).\n",
      "DEBUG:absl:Finished XLA compilation of node_sequence_residuals in 0.13316607475280762 sec\n",
      "DEBUG:absl:Finished tracing + transforming expected_node_sequence for jit in 0.013509750366210938 sec\n",
      "DEBUG:absl:Compiling expected_node_sequence (140668799736320 for args (ShapedArray(float32[5468]),).\n",
      "DEBUG:absl:Finished XLA compilation of expected_node_sequence in 0.10879731178283691 sec\n",
      "DEBUG:absl:Finished tracing + transforming <lambda> for jit in 0.00031185150146484375 sec\n",
      "DEBUG:absl:Compiling <lambda> (140668547501584 for args (ShapedArray(float32[5468]), ShapedArray(float32[5468])).\n",
      "DEBUG:absl:Finished XLA compilation of <lambda> in 0.010779142379760742 sec\n",
      "DEBUG:absl:Finished tracing + transforming transform_parameters for jit in 0.003228902816772461 sec\n",
      "DEBUG:absl:Compiling transform_parameters (140668533868736 for args (ShapedArray(float32[5468]),).\n",
      "DEBUG:absl:Finished XLA compilation of transform_parameters in 0.017004966735839844 sec\n",
      "DEBUG:absl:Finished tracing + transforming prim_fun for jit in 0.00019216537475585938 sec\n",
      "DEBUG:absl:Finished tracing + transforming prim_fun for jit in 0.0001659393310546875 sec\n",
      "DEBUG:absl:Compiling prim_fun (140668799734240 for args (ShapedArray(int32[]),).\n",
      "DEBUG:absl:Finished XLA compilation of broadcast_in_dim in 0.011259794235229492 sec\n",
      "DEBUG:absl:Finished tracing + transforming prim_fun for jit in 0.00043082237243652344 sec\n",
      "DEBUG:absl:Compiling prim_fun (140668798567600 for args (ShapedArray(float32[5468]), ShapedArray(int32[1])).\n",
      "DEBUG:absl:Finished XLA compilation of gather in 0.014651060104370117 sec\n",
      "DEBUG:absl:Finished tracing + transforming prim_fun for jit in 0.0002701282501220703 sec\n",
      "DEBUG:absl:Finished tracing + transforming prim_fun for jit in 0.0003561973571777344 sec\n",
      "DEBUG:absl:Compiling prim_fun (140668797253024 for args (ShapedArray(int32[]), ShapedArray(int32[])).\n",
      "DEBUG:absl:Finished XLA compilation of lt in 0.0062868595123291016 sec\n",
      "DEBUG:absl:Finished tracing + transforming prim_fun for jit in 0.00020813941955566406 sec\n",
      "DEBUG:absl:Compiling prim_fun (140668797289328 for args (ShapedArray(int32[]), ShapedArray(int32[])).\n",
      "DEBUG:absl:Finished XLA compilation of add in 0.008191823959350586 sec\n",
      "DEBUG:absl:Finished tracing + transforming prim_fun for jit in 0.00023794174194335938 sec\n",
      "DEBUG:absl:Compiling prim_fun (140668797289328 for args (ShapedArray(bool[]), ShapedArray(int32[]), ShapedArray(int32[])).\n",
      "DEBUG:absl:Finished XLA compilation of select_n in 0.011840105056762695 sec\n",
      "DEBUG:absl:Finished tracing + transforming prim_fun for jit in 0.0002529621124267578 sec\n",
      "DEBUG:absl:Compiling prim_fun (140668547152384 for args (ShapedArray(float32[2734]), ShapedArray(int32[1])).\n",
      "DEBUG:absl:Finished XLA compilation of gather in 0.008805274963378906 sec\n",
      "DEBUG:absl:Finished tracing + transforming fn for jit in 0.0003619194030761719 sec\n",
      "DEBUG:absl:Compiling fn (140668797289328 for args (ShapedArray(float32[]), ShapedArray(float32[])).\n",
      "DEBUG:absl:Finished XLA compilation of fn in 0.00789499282836914 sec\n",
      "DEBUG:absl:Finished tracing + transforming <lambda> for jit in 0.0003390312194824219 sec\n",
      "DEBUG:absl:Compiling <lambda> (140668799810928 for args (ShapedArray(int32[], weak_type=True), ShapedArray(float32[])).\n",
      "DEBUG:absl:Finished XLA compilation of <lambda> in 0.009053945541381836 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 79.443359375 seconds\n",
      "Relative error for expected degree/strength sequence: \n",
      "\n",
      "Percentile      Relative error\n",
      "------------  ----------------\n",
      "Min                0\n",
      "25th               1.16654e-06\n",
      "Median             2.92585e-06\n",
      "75th               7.76337e-06\n",
      "Max                0.000658751\n",
      "\n",
      "Residual error: 64.61173248291016\n"
     ]
    }
   ],
   "source": [
    "# conda install -c conda-forge jaxlib\n",
    "# conda install -c conda-forge jax\n",
    "# pip install tabulate\n",
    "\n",
    "from Backbones.ECM import ecm\n",
    "import scipy.sparse\n",
    "\n",
    "g, old_lables = convert_label_to_integers(G)\n",
    "\n",
    "W = nx.adjacency_matrix(g, weight=\"weight\")\n",
    "\n",
    "model = ecm.ECM(W)\n",
    "initial_guess = model.get_initial_guess(option=1)\n",
    "solution = model.solve(initial_guess, verbose=True)\n",
    "\n",
    "pval_M = model.get_pval_matrix(solution.x, W)\n",
    "lower_pval_M = scipy.sparse.tril(pval_M).toarray()\n",
    "\n",
    "for (i,j) in zip(*lower_pval_M.nonzero()):\n",
    "    p = lower_pval_M[i,j]\n",
    "    g[i][j]['ecm_alpha'] = p \n",
    "    \n",
    "g = relabel_nodes(g, old_lables)\n",
    "\n",
    "for u, v in G.edges():\n",
    "    G[u][v]['ecm_alpha'] = g[u][v]['ecm_alpha']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.to_pandas_edgelist(G).to_csv('../Results/All Backbones/'+network+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modularity Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Backbones import modularity_backbone as modv\n",
    "\n",
    "# k_nodes_to_remove = round(len(G.nodes())*0)\n",
    "# backbone, Q1, Q2, Q31, Q32 = modv.modularity_backbone(G, k_nodes_to_remove)\n",
    "# df_modularity = pd.DataFrame(backbone.nodes(data='modularity'), columns=['id', 'modularity']).sort_values(by='modularity', ascending=False)\n",
    "# df_modularity.to_csv('../Results/All Backbones/modularit-'+network+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23f0df36b9e21e5efa1e1be1bbc2654d2921f1d64451a6633a1922d70ec111e6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('python3.7.7-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
