{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c0ae90",
   "metadata": {},
   "source": [
    "# Need to fix the h-index. why average weighted link devided by nodes same question for betwennes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c04104",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d674ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import community.community_louvain as community\n",
    "import os, sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc11cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'lesmis'\n",
    "\n",
    "#read edge list from csv file\n",
    "edge_list = pd.read_csv('../Datasets/' + network + '.csv')\n",
    "    \n",
    "#create graph from the edge list\n",
    "G = nx.from_pandas_edgelist(edge_list, edge_attr='weight', create_using=nx.Graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a24ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Backbones import modularity_backbone as modv\n",
    "\n",
    "unlabeled_edge_list = pd.read_csv('../Datasets/'+network+'.csv', sep=',')\n",
    "g = nx.from_pandas_edgelist(unlabeled_edge_list, edge_attr='weight', create_using=nx.Graph())\n",
    "\n",
    "k_nodes_to_remove = round(len(g.nodes())*0)\n",
    "backbone, Q1, Q2, Q31, Q32 = modv.modularity_backbone(G, k_nodes_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "614bb0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(backbone.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce671f17",
   "metadata": {},
   "source": [
    "# Zakaria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cbae4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'lesmis'\n",
    "\n",
    "#read edge list from csv file\n",
    "edge_list = pd.read_csv('../Datasets/' + network + '.csv')\n",
    "    \n",
    "#create graph from the edge list\n",
    "G = nx.from_pandas_edgelist(edge_list, edge_attr='weight', create_using=nx.Graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac970ab2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'new_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y_/k_c4gj5x3rv1kmhprsdpc3lm0000gn/T/ipykernel_46388/1996995676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m############################## euroroads #######################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meuroroads\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;31m################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m############################## crime #######################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'new_data'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This module implements the disparity filter to compute a significance score of edge weights in networks\n",
    "'''\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy import integrate\n",
    "\n",
    "\n",
    "def disparity_filter(G, weight='weight'):\n",
    "    ''' Compute significance scores (alpha) for weighted edges in G as defined in Serrano et al. 2009\n",
    "        Args\n",
    "            G: Weighted NetworkX graph\n",
    "        Returns\n",
    "            Weighted graph with a significance score (alpha) assigned to each edge\n",
    "        References\n",
    "            M. A. Serrano et al. (2009) Extracting the Multiscale backbone of complex weighted networks. PNAS, 106:16, pp. 6483-6488.\n",
    "    '''\n",
    "\n",
    "    if nx.is_directed(G): #directed case\n",
    "        N = nx.DiGraph()\n",
    "        for u in G:\n",
    "\n",
    "            k_out = G.out_degree(u)\n",
    "            k_in = G.in_degree(u)\n",
    "\n",
    "            if k_out > 1:\n",
    "                sum_w_out = sum(np.absolute(G[u][v][weight]) for v in G.successors(u))\n",
    "                for v in G.successors(u):\n",
    "                    w = G[u][v][weight]\n",
    "                    p_ij_out = float(np.absolute(w))/sum_w_out\n",
    "                    alpha_ij_out = 1 - (k_out-1) * integrate.quad(lambda x: (1-x)**(k_out-2), 0, p_ij_out)[0]\n",
    "                    N.add_edge(u, v, weight = w, alpha_out=float('%.4f' % alpha_ij_out))\n",
    "\n",
    "            elif k_out == 1 and G.in_degree(G.successors(u)[0]) == 1:\n",
    "                #we need to keep the connection as it is the only way to maintain the connectivity of the network\n",
    "                v = G.successors(u)[0]\n",
    "                w = G[u][v][weight]\n",
    "                N.add_edge(u, v, weight = w, alpha_out=0., alpha_in=0.)\n",
    "                #there is no need to do the same for the k_in, since the link is built already from the tail\n",
    "\n",
    "            if k_in > 1:\n",
    "                sum_w_in = sum(np.absolute(G[v][u][weight]) for v in G.predecessors(u))\n",
    "                for v in G.predecessors(u):\n",
    "                    w = G[v][u][weight]\n",
    "                    p_ij_in = float(np.absolute(w))/sum_w_in\n",
    "                    alpha_ij_in = 1 - (k_in-1) * integrate.quad(lambda x: (1-x)**(k_in-2), 0, p_ij_in)[0]\n",
    "                    N.add_edge(v, u, weight = w, alpha_in=float('%.4f' % alpha_ij_in))\n",
    "        return N\n",
    "\n",
    "    else: #undirected case\n",
    "        B = nx.Graph()\n",
    "        for u in G:\n",
    "            k = len(G[u])\n",
    "            if k > 1:\n",
    "                sum_w = sum(np.absolute(G[u][v][weight]) for v in G[u])\n",
    "                for v in G[u]:\n",
    "                    w = G[u][v][weight]\n",
    "                    p_ij = float(np.absolute(w))/sum_w\n",
    "                    alpha_ij = 1 - (k-1) * integrate.quad(lambda x: (1-x)**(k-2), 0, p_ij)[0]\n",
    "                    B.add_edge(u, v, weight = w, alpha=float('%.4f' % alpha_ij))\n",
    "        return B\n",
    "\n",
    "def disparity_filter_alpha_cut(G,weight='weight',alpha_t=0.4, cut_mode='or'):\n",
    "    ''' Performs a cut of the graph previously filtered through the disparity_filter function.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        G: Weighted NetworkX graph\n",
    "\n",
    "        weight: string (default='weight')\n",
    "            Key for edge data used as the edge weight w_ij.\n",
    "\n",
    "        alpha_t: double (default='0.4')\n",
    "            The threshold for the alpha parameter that is used to select the surviving edges.\n",
    "            It has to be a number between 0 and 1.\n",
    "\n",
    "        cut_mode: string (default='or')\n",
    "            Possible strings: 'or', 'and'.\n",
    "            It works only for directed graphs. It represents the logic operation to filter out edges\n",
    "            that do not pass the threshold value, combining the alpha_in and alpha_out attributes\n",
    "            resulting from the disparity_filter function.\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        B: Weighted NetworkX graph\n",
    "            The resulting graph contains only edges that survived from the filtering with the alpha_t threshold\n",
    "\n",
    "        References\n",
    "        ---------\n",
    "        .. M. A. Serrano et al. (2009) Extracting the Multiscale backbone of complex weighted networks. PNAS, 106:16, pp. 6483-6488.\n",
    "    '''\n",
    "\n",
    "\n",
    "    if nx.is_directed(G):#Directed case:\n",
    "        B = nx.DiGraph()\n",
    "        for u, v, w in G.edges(data=True):\n",
    "            try:\n",
    "                alpha_in =  w['alpha_in']\n",
    "            except KeyError: #there is no alpha_in, so we assign 1. It will never pass the cut\n",
    "                alpha_in = 1\n",
    "            try:\n",
    "                alpha_out =  w['alpha_out']\n",
    "            except KeyError: #there is no alpha_out, so we assign 1. It will never pass the cut\n",
    "                alpha_out = 1\n",
    "\n",
    "            if cut_mode == 'or':\n",
    "                if alpha_in<alpha_t or alpha_out<alpha_t:\n",
    "                    B.add_edge(u,v, weight=w[weight])\n",
    "            elif cut_mode == 'and':\n",
    "                if alpha_in<alpha_t and alpha_out<alpha_t:\n",
    "                    B.add_edge(u,v, weight=w[weight])\n",
    "        return B\n",
    "\n",
    "    else:\n",
    "        B = nx.Graph()#Undirected case:\n",
    "        for u, v, w in G.edges(data=True):\n",
    "\n",
    "            try:\n",
    "                alpha = w['alpha']\n",
    "            except KeyError: #there is no alpha, so we assign 1. It will never pass the cut\n",
    "                alpha = 1\n",
    "\n",
    "            if alpha<alpha_t:\n",
    "                B.add_edge(u,v, weight=w[weight])\n",
    "        return B\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #from data_karate import *\n",
    "    #from data_Lesmiserables import *\n",
    "    #from data_dolphin import *\n",
    "    #from data_got import *\n",
    "    #from data_football import *\n",
    "    #from data_egofacebook import *\n",
    "    #from data_grqc import *\n",
    "    #from data_HepTh import *\n",
    "    #from data_CondMat import *\n",
    "    #from data_enronemail import *\n",
    "\n",
    "    ###################### Karate club ##################################\n",
    "    #from data_karate import *\n",
    "    ######################################################################\n",
    "    ###################### Les Miserables ##################################\n",
    "    #from data_Lesmiserables import *\n",
    "    ######################################################################\n",
    "    ###################### Daulphins #####################################\n",
    "    #from data_dolphin import *\n",
    "    ########################################################################\n",
    "    ###################### Game of thrones ################################\n",
    "    #from data_got import *\n",
    "    ######################################################################\n",
    "    ###################### football ######################################\n",
    "    #from data_football import *\n",
    "    ######################################################################\n",
    "    #####################################################################\n",
    "    #from new_data.terrorist import *\n",
    "    ################################################################################\n",
    "    #####################################################################\n",
    "    #from new_data.ecologie import *\n",
    "    ################################################################################\n",
    "    #####################################################################\n",
    "    #from new_data.adjnoun import *\n",
    "    ################################################################################\n",
    "    ############################## euroroads #######################################\n",
    "    from new_data.euroroads import *\n",
    "    ################################################################################\n",
    "    ############################## crime #######################################\n",
    "    #from new_data.crime import *\n",
    "    ################################################################################\n",
    "\n",
    "    #G = nx.barabasi_albert_graph(1000, 5)\n",
    "    #G=nx.karate_club_graph()\n",
    "    G=g\n",
    "\n",
    "    for u, v in G.edges():\n",
    "        G[u][v]['weight'] = np.random.randint(1,100)\n",
    "    alpha = 0.2\n",
    "    G = disparity_filter(G)\n",
    "    G2 = nx.Graph([(u, v, d) for u, v, d in G.edges(data=True) if d['alpha'] < alpha])\n",
    "    print ('alpha = %s' % alpha)\n",
    "    print ('original: nodes = %s, edges = %s' % (G.number_of_nodes(), G.number_of_edges()))\n",
    "    print ('backbone: nodes = %s, edges = %s' % (G2.number_of_nodes(), G2.number_of_edges()))\n",
    "    print (G2.edges(data=True))\n",
    "    print(G2.nodes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e055fd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'backbone'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y_/k_c4gj5x3rv1kmhprsdpc3lm0000gn/T/ipykernel_46388/1631967261.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mintegrate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbackbone\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmethods_overlapping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjaccard_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'backbone'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy import integrate\n",
    "from backbone import *\n",
    "from methods_overlapping import *\n",
    "from sklearn.metrics import jaccard_score\n",
    "from slpa import *\n",
    "import math\n",
    "\n",
    "\n",
    "#Networks:\n",
    "#  -------\n",
    "\n",
    "#g=nx.read_pajek('karate_club_weighted.net')\n",
    "\n",
    "g=nx.read_weighted_edgelist(r'C:\\Users\\HP\\Desktop\\Programme1\\Backbone2\\weightedNets\\karate_club_weighted.dat')\n",
    "network='weightedNets/karate_club_weighted.dat'\n",
    "\n",
    "#g = nx.read_gml(r'C:\\Users\\HP\\Desktop\\Programme1\\Backbone2\\weightedNets\\lesmis.gml')\n",
    "#network='weightedNets/lesmis.gml'\n",
    "\n",
    "#g=nx.read_weighted_edgelist('weightedNets/got.dat')\n",
    "#network='weightedNets/got.dat'\n",
    "\n",
    "#g=nx.read_weighted_edgelist('weightedNets/train.dat')\n",
    "#network='weightedNets/train.dat'\n",
    "\n",
    "#g=nx.read_weighted_edgelist('toy.dat')\n",
    "#g=nx.read_weighted_edgelist('USairoport.dat')\n",
    "\n",
    "#g=nx.read_weighted_edgelist('weightedNets/Caenorhabditis.dat')\n",
    "#g=nx.read_weighted_edgelist('weightedNets/Davis_southern_club_women.dat')\n",
    "#g=nx.read_weighted_edgelist('weightedNets/Facebook-likeForum.dat')\n",
    "#g=nx.read_weighted_edgelist('weightedNets/Facebook-likeSocial.dat')\n",
    "#g=nx.read_weighted_edgelist('weightedNets/FreemansEIES.dat')\n",
    "#network='weightedNets/FreemansEIES.dat'\n",
    "\n",
    "#g=nx.read_weighted_edgelist('weightedNets/Intra-organisational.dat')\n",
    "#network='weightedNets/Intra-organisational.dat'\n",
    "\n",
    "#g=nx.read_weighted_edgelist('weightedNets/scientificCollaboration.dat')\n",
    "#g=nx.read_weighted_edgelist('weightedNets/USpowergrid.dat')\n",
    "#network='weightedNets/USpowergrid.dat'\n",
    "\n",
    "#g=nx.read_weighted_edgelist('weightedNets/Davis_southern_club_women2.dat')\n",
    "#g=nx.read_weighted_edgelist('weightedNets/Intra-organisational2.dat')\n",
    "#g=nx.read_weighted_edgelist('weightedNets/Intra-organisational3.dat')\n",
    "#g=nx.read_weighted_edgelist('weightedNets/Intra-organisational4.dat')\n",
    "#g=nx.read_weighted_edgelist('weightedNets/scientificCollaboration2.dat')\n",
    "\n",
    "#  Alpha :\n",
    "#  -----\n",
    "alpha = 0.9\n",
    "\n",
    "#  mu :\n",
    "#  -----\n",
    "mu = 0.5 #tuning parameter for degree centrality\n",
    "\n",
    "s=0.3\n",
    "\n",
    "ep=6.0\n",
    "ITcommunityfinder=1\n",
    "width=12\n",
    "hight=12\n",
    "w=12\n",
    "h=12\n",
    "\n",
    "width_o=15\n",
    "hight_o=15\n",
    "\n",
    "\n",
    "\n",
    "#colors=['Green', 'Red', 'blue', '#CD853F', '#87CEEB', 'Maroon', 'orange', 'purple', 'Yellow', 'Gray']\n",
    "colors=['Green', 'Maroon', 'Red', 'blue', 'orange', 'purple', '#87CEEB', '#CD853F', 'Gray', 'Yellow']\n",
    "#colors=['Red', 'Green', 'blue', '#CD853F', '#87CEEB', 'Maroon', 'orange', 'purple', 'Yellow', 'Gray']\n",
    "\n",
    "########################### The graph #####################################\"\"\n",
    "l_nodes=g.nodes() #list of nodes\n",
    "dict_graph=dict()\n",
    "for i in g:\n",
    "    dict_graph[i]=[]\n",
    "    for j in g[i]:\n",
    "        dict_graph[i].append(j)\n",
    "print('dict_graph=',dict_graph) #dict(node: neighbors)\n",
    "\n",
    "\n",
    "\n",
    "############ dict_tri= node: degree sorted #####################################\n",
    "list_edges=g.edges(data=True) # list: list_edges=[(original node, destination node, weight)]\n",
    "print('list_edges=',list_edges)\n",
    "\n",
    "dict_strength=dict() #dict(node: its total weight)\n",
    "for i in l_nodes:\n",
    "    dict_strength[i]=0\n",
    "    for e in list_edges:\n",
    "        if (e[0]==i) or (e[1]==i):\n",
    "            dict_strength[i]=dict_strength[i]+e[2]['weight']\n",
    "            #dict_strength[i]=dict_strength[i]+e[2]['value']\n",
    "print('dict_strength=',dict_strength)\n",
    "\n",
    "d_degree=nx.degree_centrality(g) #d_degree=dict(node:degree)\n",
    "#print('d_degree=',d_degree)\n",
    "\n",
    "#mu=0.5  #tuning parameter\n",
    "mu1=1-mu\n",
    "dict_degree=dict()\n",
    "for i in l_nodes:\n",
    "    dict_degree[i]=(math.pow(d_degree[i],mu1))*(math.pow(dict_strength[i],mu))\n",
    "\n",
    "# le tri\n",
    "d = dict_degree\n",
    "l = []\n",
    "for i in d:\n",
    "    l.append (i)\n",
    "n = len (d)\n",
    "\n",
    "for i in range (0, n - 1):\n",
    "    max = i\n",
    "    for j in range (i + 1, n):\n",
    "        if d[l[max]] < d[l[j]]:\n",
    "            max = j\n",
    "    if max != i:\n",
    "        x = l[i]\n",
    "        l[i] = l[max]\n",
    "        l[max] = x\n",
    "dict_tri = dict ()\n",
    "for i in l:\n",
    "    dict_tri[i] = d[i]\n",
    "#\"\"\"\n",
    "dict_degree=dict_tri\n",
    "#print('List of nodes sorted by degree:',l)\n",
    "print('dict_tri=',dict_tri)\n",
    "print('dict_degree=',dict_tri)\n",
    "#\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\"\"\"\n",
    "############### détecter les communautés avec SLPA #############################\n",
    "c = find_communities(g,ITcommunityfinder,0.01)  # compute communities\n",
    "#la liste des partition:\n",
    "i=0\n",
    "keysp=list()\n",
    "for j in c:\n",
    "    keysp.append(i)\n",
    "    i=i+1\n",
    "#print(keysp)\n",
    "\n",
    "# calculer dictionnaire partition = partition:list of nodes\n",
    "partition=dict()\n",
    "for i in keysp:\n",
    "    partition[i]=[]\n",
    "i=0\n",
    "for j in c:\n",
    "    for k in c[j]:\n",
    "        partition[i].append(k)\n",
    "    i=i+1\n",
    "print('partition_nodes=',partition)\n",
    "print('partition=',partition)\n",
    "print('nc=',len(partition))\n",
    "d_community=partition\n",
    "#\"\"\"\n",
    "############ list_over=list of overlapping nodes ###############################\n",
    "lo,membership,do=list_overlapping(g,d_community)\n",
    "print('membership=',membership) #node:membership\n",
    "print('lo= ',lo)\n",
    "#\"\"\"\n",
    "############ dict_over=Overlapping node:list of its neighbors ##################\n",
    "dict_over=dict()\n",
    "for i in lo:\n",
    "    dict_over[i]=dict_graph[i]\n",
    "############ Neighbor_over_tri=list of the neighbors of all the overlapping nodes sorted #\n",
    "Neighbor_over=list()\n",
    "ln=list()\n",
    "for i in lo:\n",
    "    for j in dict_graph[i]:\n",
    "        ln.append(j)\n",
    "\n",
    "Neighbor_over=list(set(ln))\n",
    "\n",
    "d=dict()\n",
    "for i in Neighbor_over:\n",
    "    d[i]=dict_tri[i]\n",
    "n = len (d)\n",
    "for i in range (0, n - 1):\n",
    "    max = i\n",
    "    for j in range (i + 1, n):\n",
    "        if d[Neighbor_over[max]] < d[Neighbor_over[j]]:\n",
    "            max = j\n",
    "    if max != i:\n",
    "        x = Neighbor_over[i]\n",
    "        Neighbor_over[i] = Neighbor_over[max]\n",
    "        Neighbor_over[max] = x\n",
    "Neighbor_over_tri=dict()\n",
    "for i in Neighbor_over:\n",
    "    Neighbor_over_tri[i] = dict_tri[i]\n",
    "\n",
    "print('Neighbor_over_tri= ',Neighbor_over_tri)\n",
    "#print('ego=',len(list(Neighbor_over_tri))/len(list(dict_graph)))\n",
    "#\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################# Original network ####################################\n",
    "###################  node_community= node: list of its partitions #######################\n",
    "partition2=dict()\n",
    "for i in dict_graph:\n",
    "    partition2[i]=[]\n",
    "for i in dict_graph:\n",
    "    for j in partition:\n",
    "        if (partition[j].count(i)!=0):\n",
    "            partition2[i].append(j)\n",
    "node_community=partition2 #dict(node: list of its partitions)\n",
    "################ partition_color= partition: color #############################\n",
    "partition_color=dict()\n",
    "k=0\n",
    "for i in partition:\n",
    "    partition_color[i]=colors[k]\n",
    "    k=k+1\n",
    "################ node_color= node:color ########################################\n",
    "node_color=dict()\n",
    "for i in g:\n",
    "    n=node_community[i]\n",
    "    node_color[i]=partition_color[n[0]]\n",
    "\n",
    "list_colors=[]\n",
    "for i in g:\n",
    "    if lo.count(i)==1:\n",
    "        list_colors.append('#F5F5F5')\n",
    "    else:\n",
    "        list_colors.append(node_color[i])\n",
    "\n",
    "\n",
    "############### Draw the original network ###############################################\n",
    "d=dict_degree\n",
    "\n",
    "#g=g_inter\n",
    "d2=dict()\n",
    "for i in g:\n",
    "    d2[i]=d[i]\n",
    "\n",
    "\n",
    "plt.subplots_adjust(left = 0.01, bottom = 0.01, right = 0.99, top = 0.99)\n",
    "plt.figure(figsize=(width_o,hight_o))  # image is 8 x 8 inches\n",
    "plt.axis('off')\n",
    "\n",
    "# edges\n",
    "all_weights = []\n",
    "for (node1,node2,data) in g.edges(data=True):\n",
    "    #print('node1,node2,data: ',data)\n",
    "    all_weights.append(data['weight']) #we'll use this when determining edge thickness\n",
    "\n",
    "#4 b. Get unique weights\n",
    "unique_weights = list(set(all_weights))\n",
    "#pos=nx.circular_layout(g)\n",
    "pos=nx.spring_layout(g)\n",
    "#4 c. Plot the edges - one by one!\n",
    "node_list=g.nodes()\n",
    "for weight in unique_weights:\n",
    "    weighted_edges = [(node1,node2) for (node1,node2,edge_attr) in g.edges(data=True) if edge_attr['weight']==weight]\n",
    "    width = weight*len(node_list)*ep/sum(all_weights)\n",
    "    nx.draw_networkx_edges(g,pos,edgelist=weighted_edges,width=width)\n",
    "a=len(node_list)*ep\n",
    "b=sum(all_weights)\n",
    "\n",
    "nx.draw_networkx(g, pos, with_labels=True, node_size=[v * 80 for v in d2.values()] , node_color=list_colors, font_size=12, font_color='k', font_family='sans-serif', font_weight='bold')\n",
    "\n",
    "plt.savefig('0OriginalNetwork.png',dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################# Global Component ####################################\n",
    "#print('1',g.edges(data=True))\n",
    "# Le graph(graph_inter)+dictionnaire(g_inter) intra des noeuds overlapping et non-overlapping\n",
    "g_inter=globalComponent(g,partition)\n",
    "#print('global component dictionary: ',g_inter)\n",
    "#print(nx.info(graph_inter))\n",
    "ss1=0\n",
    "ss2=0\n",
    "for e in g.edges(data=True):\n",
    "    ss1=ss1+e[2]['weight']\n",
    "for e in g_inter.edges(data=True):\n",
    "    ss2=ss2+e[2]['weight']\n",
    "print('Mixing parameter weighted: ',ss2/ss1)\n",
    "print('Mixing parameter: ',len(list(g_inter.edges(data=True)))/len(list(g.edges(data=True))))\n",
    "print('Global component: ',g_inter.edges(data=True))\n",
    "\n",
    "################### Drawing the Global Component ###############################\n",
    "g1=g_inter\n",
    "###################  node_community= node: list of its partitions #######################\n",
    "partition2=dict()\n",
    "for i in dict_graph:\n",
    "    partition2[i]=[]\n",
    "for i in dict_graph:\n",
    "    for j in partition:\n",
    "        if (partition[j].count(i)!=0):\n",
    "            partition2[i].append(j)\n",
    "#print('partition2=',partition2)\n",
    "node_community=partition2 #dict(node: list of its partitions)\n",
    "################ partition_color= partition: color #############################\n",
    "partition_color=dict()\n",
    "k=0\n",
    "for i in partition:\n",
    "    partition_color[i]=colors[k]\n",
    "    k=k+1\n",
    "################ node_color= node:color ########################################\n",
    "node_color=dict()\n",
    "\n",
    "for i in g1:\n",
    "    n=node_community[i]\n",
    "    node_color[i]=partition_color[n[0]]\n",
    "\n",
    "list_colors=[]\n",
    "\n",
    "for i in g1:\n",
    "    if lo.count(i)==1:\n",
    "        list_colors.append('#F5F5F5')\n",
    "    else:\n",
    "        list_colors.append(node_color[i])\n",
    "\n",
    "\n",
    "\n",
    "############### Draw the figure of the global component ########################\n",
    "d=dict_degree\n",
    "\n",
    "#g1=g_inter\n",
    "d2=dict()\n",
    "for i in g1:\n",
    "    d2[i]=d[i]\n",
    "\n",
    "plt.subplots_adjust(left = 0.01, bottom = 0.01, right = 0.99, top = 0.99)\n",
    "plt.figure(figsize=(w, h))  # image is 8 x 8 inches\n",
    "plt.axis('off')\n",
    "\n",
    "# edges\n",
    "all_weights = []\n",
    "for (node1,node2,data) in g1.edges(data=True):\n",
    "    #print('node1,node2,data: ',data)\n",
    "    all_weights.append(data['weight']) #we'll use this when determining edge thickness\n",
    "\n",
    "#4 b. Get unique weights\n",
    "unique_weights = list(set(all_weights))\n",
    "pos=nx.circular_layout(g1)\n",
    "#pos=nx.spring_layout(g1)\n",
    "#4 c. Plot the edges - one by one!\n",
    "node_list=g1.nodes()\n",
    "for weight in unique_weights:\n",
    "    weighted_edges = [(node1,node2) for (node1,node2,edge_attr) in g1.edges(data=True) if edge_attr['weight']==weight]\n",
    "    width = weight*len(node_list)*ep/sum(all_weights)\n",
    "    nx.draw_networkx_edges(g1,pos,edgelist=weighted_edges,width=width)\n",
    "a=len(node_list)*ep\n",
    "b=sum(all_weights)\n",
    "\n",
    "nx.draw_networkx(g1, pos, with_labels=True, node_size=[v * 80 for v in d2.values()] , node_color=list_colors, font_size=12, font_color='k', font_family='sans-serif', font_weight='bold')\n",
    "\n",
    "plt.savefig('1globalComponent.png',dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############ Extract the Serrano backbone of the Global component ###############\n",
    "for u, v in g1.edges():\n",
    "    g1[u][v]['weight'] = np.random.randint(1,100)\n",
    "\n",
    "# Filter and new serrano backbone\n",
    "g1 = disparity_filter(g1)\n",
    "g2 = nx.Graph([(u, v, d) for u, v, d in g1.edges(data=True) if d['alpha'] < alpha])\n",
    "print ('alpha = %s' % alpha)\n",
    "#print ('original: nodes = %s, edges = %s' % (g.number_of_nodes(), g.number_of_edges()))\n",
    "print ('Serrano backbone of the GC: nodes = %s, edges = %s' % (g2.number_of_nodes(), g2.number_of_edges()))\n",
    "print ('Edges of serrano GC: ',g2.edges(data=True))\n",
    "print('Nodes of serrano GC: ',g2.nodes())\n",
    "l_edgesSerrano=list(g2.edges(data=True))\n",
    "\n",
    "\n",
    "\n",
    "################## Drawing Serrano backbone of the Global Component ############\n",
    "e=g2.edges(data=True)\n",
    "g=nx.Graph()\n",
    "ee=[(i[0],i[1]) for i in g.edges(data=True)]\n",
    "for i in e:\n",
    "    ee.append((i[0],i[1]))\n",
    "\n",
    "g1=nx.read_weighted_edgelist(network)\n",
    "dict_weights=dict()\n",
    "for i in g1.edges(data=True):\n",
    "    dict_weights[(i[0],i[1])]=i[2]['weight']\n",
    "\n",
    "e2=[]\n",
    "for i in ee:\n",
    "    if list(dict_weights).count((i[0],i[1]))!=0:\n",
    "        e2.append((i[0],i[1],dict_weights[(i[0],i[1])]))\n",
    "    else:\n",
    "        e2.append((i[0],i[1],dict_weights[(i[1],i[0])]))\n",
    "#print(ee)\n",
    "#print(e2)\n",
    "g.add_weighted_edges_from(e2)\n",
    "\n",
    "d=dict_degree\n",
    "\n",
    "d2=dict()\n",
    "for i in g:\n",
    "    d2[i]=d[i]\n",
    "\n",
    "\n",
    "\n",
    "G=g\n",
    "#print('huuu',G.edges(data=True))\n",
    "elarge = [(u, v) for (u, v, d) in G.edges(data=True) if d['weight'] > 20]\n",
    "esmall = [(u, v) for (u, v, d) in G.edges(data=True) if d['weight'] <= 20]\n",
    "\n",
    "\n",
    "plt.subplots_adjust(left = 0.01, bottom = 0.01, right = 0.99, top = 0.99)\n",
    "plt.figure(figsize=(w, h))  # image is 8 x 8 inches\n",
    "\n",
    "#pos = nx.spring_layout(G)  # positions for all nodes\n",
    "#pos=nx.shell_layout(G)\n",
    "pos=nx.circular_layout(G)\n",
    "\n",
    "################ node_color= node:color ########################################\n",
    "node_color=dict()\n",
    "\n",
    "for i in G:\n",
    "    n=node_community[i]\n",
    "    node_color[i]=partition_color[n[0]]\n",
    "\n",
    "list_colors=[]\n",
    "\n",
    "for i in G:\n",
    "    if lo.count(i)==1:\n",
    "        list_colors.append('#F5F5F5')\n",
    "    else:\n",
    "        list_colors.append(node_color[i])\n",
    "\n",
    "# nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_size=[v * 80 for v in d2.values()], node_color=list_colors)\n",
    "\n",
    "# edges\n",
    "all_weights = []\n",
    "#4 a. Iterate through the graph nodes to gather all the weights\n",
    "for (node1,node2,data) in G.edges(data=True):\n",
    "    all_weights.append(data['weight']) #we'll use this when determining edge thickness\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(g2.edges(data=True))\n",
    "node_list2=g2.nodes()\n",
    "all_weights2 = []\n",
    "s2=0\n",
    "for (node1,node2,data) in g2.edges(data=True):\n",
    "    all_weights2.append(data['weight']) #we'll use this when determining edge thickness\n",
    "    s2=s2+data['weight']\n",
    "#4 b. Get unique weights\n",
    "unique_weights = list(set(all_weights))\n",
    "\n",
    "#4 c. Plot the edges - one by one!\n",
    "node_list=G.nodes()\n",
    "for i in G.edges(data=True):\n",
    "    if list(dict_weights).count((i[0],i[1]))!=0:\n",
    "        weight=dict_weights[(i[0],i[1])]\n",
    "    else:\n",
    "        weight=dict_weights[(i[1],i[0])]\n",
    "    #4 d. Form a filtered list with just the weight you want to draw\n",
    "    weighted_edges = [(node1,node2) for (node1,node2,edge_attr) in G.edges(data=True) if edge_attr['weight']==weight]\n",
    "    #4 e. I think multiplying by [num_nodes/sum(all_weights)] makes the graphs edges look cleaner\n",
    "    width = weight*a/b\n",
    "    nx.draw_networkx_edges(G,pos,edgelist=weighted_edges,width=width)\n",
    "\n",
    "\n",
    "# labels\n",
    "nx.draw_networkx_labels(G, pos, node_size=[v * 80 for v in d2.values()], node_color=list_colors, font_size=12, font_color='k', font_family='sans-serif', font_weight='bold')\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig('2serrano1.png',dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################## Overlap-Hub backbone ##############################\n",
    "g = nx.read_weighted_edgelist(network)\n",
    "l_nodes=g.nodes() #list of nodes\n",
    "dict_graph=dict()\n",
    "for i in g:\n",
    "    dict_graph[i]=[]\n",
    "    for j in g[i]:\n",
    "        dict_graph[i].append(j)\n",
    "\n",
    "networksize=int(len(list(g.nodes()))*s)\n",
    "\n",
    "# extracting the list of hubs\n",
    "size=len(Neighbor_over_tri)\n",
    "l_hubs=list(dict_degree)\n",
    "l_hubs=list_extract2(l_hubs,size)\n",
    "\n",
    "# ego network\n",
    "l_ego=list(set(l_hubs+lo))\n",
    "dict_ego=dict()\n",
    "for i in l_ego:\n",
    "    dict_ego[i]=dict_tri[i]\n",
    "d = dict_ego\n",
    "l = []\n",
    "for i in d:\n",
    "    l.append (i)\n",
    "n = len (d)\n",
    "\n",
    "for i in range (0, n - 1):\n",
    "    max = i\n",
    "    for j in range (i + 1, n):\n",
    "        if d[l[max]] < d[l[j]]:\n",
    "            max = j\n",
    "    if max != i:\n",
    "        x = l[i]\n",
    "        l[i] = l[max]\n",
    "        l[max] = x\n",
    "dict_tri = dict ()\n",
    "for i in l:\n",
    "    dict_tri[i] = d[i]\n",
    "dict_ego=dict_tri\n",
    "\n",
    "dict_ego=dict_extract(dict_ego,networksize)\n",
    "\n",
    "l_nodes=list(dict_graph)\n",
    "\n",
    "dict_graph=immunize2(dict_graph,dict_ego,l_nodes)\n",
    "#print('dict_graph',dict_graph)\n",
    "\n",
    "\n",
    "g_OH=nx.Graph()\n",
    "l_edges=[]\n",
    "for i in dict_graph:\n",
    "    for j in dict_graph[i]:\n",
    "        l_edges.append((i,j))\n",
    "\n",
    "for li in l_edges:\n",
    "    l_edges.remove((li[1],li[0]))\n",
    "#print('l_edges=',l_edges)\n",
    "\n",
    "g = nx.read_weighted_edgelist(network)\n",
    "#print('lalala',g.edges(data=True))\n",
    "l_edges2=[]\n",
    "edges_sorted=dict()\n",
    "for e in l_edges:\n",
    "    #print(e)\n",
    "    for v in g.edges(data=True):\n",
    "        #print(node1,node2,data)\n",
    "        if (e[0]==v[0] and e[1]==v[1]) or (e[0]==v[1] and e[1]==v[0]):\n",
    "            #l_edges2.append((e[0],e[1],data['weight']))\n",
    "            l_edges2.append((e[0],e[1],v[2]['weight']))\n",
    "            edges_sorted[(e[0],e[1])]=v[2]['weight']\n",
    "\n",
    "g_OH.add_weighted_edges_from(l_edges2)\n",
    "\n",
    "\n",
    "\n",
    "d = edges_sorted\n",
    "l = []\n",
    "for i in d:\n",
    "    l.append (i)\n",
    "n = len (d)\n",
    "\n",
    "for i in range (0, n - 1):\n",
    "    max = i\n",
    "    for j in range (i + 1, n):\n",
    "        if d[l[max]] > d[l[j]]:\n",
    "            max = j\n",
    "    if max != i:\n",
    "        x = l[i]\n",
    "        l[i] = l[max]\n",
    "        l[max] = x\n",
    "dict_t = dict ()\n",
    "for i in l:\n",
    "    dict_t[i] = d[i]\n",
    "edges_sorted=dict_t\n",
    "\n",
    "\n",
    "l_lcc=list()\n",
    "for i in edges_sorted:\n",
    "    x=i\n",
    "    g_OH.remove_edges_from([i])\n",
    "    l_lcc=list(nx.connected_components(g_OH))\n",
    "    if (len(l_lcc)>1):\n",
    "        g_OH.add_weighted_edges_from([(x[0],x[1],edges_sorted[(x[0],x[1])])])\n",
    "        continue\n",
    "l_edgesOH=list(g_OH.edges(data=True))\n",
    "print('l_edgesOH=',list(g_OH.edges(data=True)))\n",
    "print('size OH: ',len(list(g_OH.nodes())))\n",
    "\n",
    "################ node_color= node:color ########################################\n",
    "node_color=dict()\n",
    "\n",
    "for i in g_OH:\n",
    "    n=node_community[i]\n",
    "    node_color[i]=partition_color[n[0]]\n",
    "\n",
    "list_colors=[]\n",
    "\n",
    "for i in g_OH:\n",
    "    if lo.count(i)==1:\n",
    "        list_colors.append('#F5F5F5')\n",
    "    else:\n",
    "        list_colors.append(node_color[i])\n",
    "\n",
    "\n",
    "\n",
    "############### Draw the figure of the global component ########################\n",
    "d=dict_degree\n",
    "\n",
    "#g1=g_inter\n",
    "d2=dict()\n",
    "for i in g_OH:\n",
    "    d2[i]=d[i]\n",
    "\n",
    "\n",
    "plt.subplots_adjust(left = 0.01, bottom = 0.01, right = 0.99, top = 0.99)\n",
    "plt.figure(figsize=(w, h))  # image is 8 x 8 inches\n",
    "plt.axis('off')\n",
    "\n",
    "# edges\n",
    "all_weights = []\n",
    "for (node1,node2,data) in g_OH.edges(data=True):\n",
    "    #print('node1,node2,data: ',data)\n",
    "    all_weights.append(data['weight']) #we'll use this when determining edge thickness\n",
    "\n",
    "#4 b. Get unique weights\n",
    "unique_weights = list(set(all_weights))\n",
    "pos=nx.circular_layout(g_OH)\n",
    "#pos=nx.spring_layout(g1)\n",
    "#4 c. Plot the edges - one by one!\n",
    "node_list=g_OH.nodes()\n",
    "for weight in unique_weights:\n",
    "    weighted_edges = [(node1,node2) for (node1,node2,edge_attr) in g_OH.edges(data=True) if edge_attr['weight']==weight]\n",
    "    width = weight*len(node_list)*ep/sum(all_weights)\n",
    "    nx.draw_networkx_edges(g_OH,pos,edgelist=weighted_edges,width=width)\n",
    "a=len(node_list)*ep\n",
    "b=sum(all_weights)\n",
    "\n",
    "nx.draw_networkx(g_OH, pos, with_labels=True, node_size=[v * 80 for v in d2.values()] , node_color=list_colors, font_size=12, font_color='k', font_family='sans-serif', font_weight='bold')\n",
    "\n",
    "plt.savefig('4OH.png',dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "l_edgesInter=[]\n",
    "for e1 in l_edgesSerrano:\n",
    "    for e2 in l_edgesOH:\n",
    "        if ((e1[0]==e2[0]) and (e1[1]==e2[1])) or ((e1[0]==e2[1]) and (e1[1]==e2[0])):\n",
    "            for v in g.edges(data=True):\n",
    "                if (e1[0]==v[0] and e1[1]==v[1]) or (e1[0]==v[1] and e1[1]==v[0]):\n",
    "                    l_edgesInter.append((e1[0],e1[1],v[2]['weight']))\n",
    "            #l_edgesInter.append(e1)\n",
    "print('l_edgesInter: ',l_edgesInter)\n",
    "g_Inter=nx.Graph()\n",
    "g_Inter.add_weighted_edges_from(l_edgesInter)\n",
    "l_inter=list(g_Inter.nodes())\n",
    "print('edges Inter: ',list(g_Inter.edges(data=True)))\n",
    "\n",
    "print('Nodes inter: ',set(list(g_OH.nodes()))&set(list(G.nodes())))\n",
    "l_int=list(set(list(g_OH.nodes()))&set(list(G.nodes())))\n",
    "l_del=list(set(list(G.nodes())))\n",
    "for i in l_int:\n",
    "    l_del.remove(i)\n",
    "\n",
    "size_serr=len(l_del)\n",
    "networksize=networksize-size_serr\n",
    "\n",
    "\n",
    "edges_serrano=list(G.edges(data=True))\n",
    "#print('edges_serrano',edges_serrano)\n",
    "for e in list(g_Inter.edges(data=True)):\n",
    "    edges_serrano.remove(e)\n",
    "\n",
    "################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# ego network\n",
    "\n",
    "\n",
    "dict_ego=dict_extract(dict_ego,networksize)\n",
    "l_nodes=list(dict_graph)\n",
    "\n",
    "dict_graph=immunize2(dict_graph,dict_ego,l_nodes)\n",
    "#print('dict_graph',dict_graph)\n",
    "\n",
    "\n",
    "g_OH2=nx.Graph()\n",
    "l_edges=[]\n",
    "for i in dict_graph:\n",
    "    for j in dict_graph[i]:\n",
    "        l_edges.append((i,j))\n",
    "\n",
    "for li in l_edges:\n",
    "    l_edges.remove((li[1],li[0]))\n",
    "print('l_edges=',l_edges)\n",
    "\n",
    "\n",
    "\n",
    "l_edges2=[]\n",
    "edges_sorted=dict()\n",
    "for e in l_edges:\n",
    "    #print(e)\n",
    "    for v in g.edges(data=True):\n",
    "        #print(node1,node2,data)\n",
    "        if (e[0]==v[0] and e[1]==v[1]) or (e[0]==v[1] and e[1]==v[0]):\n",
    "            #l_edges2.append((e[0],e[1],data['weight']))\n",
    "            l_edges2.append((e[0],e[1],v[2]['weight']))\n",
    "            edges_sorted[(e[0],e[1])]=v[2]['weight']\n",
    "\n",
    "g_OH2.add_weighted_edges_from(l_edges2)\n",
    "\n",
    "\n",
    "\n",
    "d = edges_sorted\n",
    "l = []\n",
    "for i in d:\n",
    "    l.append (i)\n",
    "n = len (d)\n",
    "\n",
    "for i in range (0, n - 1):\n",
    "    max = i\n",
    "    for j in range (i + 1, n):\n",
    "        if d[l[max]] > d[l[j]]:\n",
    "            max = j\n",
    "    if max != i:\n",
    "        x = l[i]\n",
    "        l[i] = l[max]\n",
    "        l[max] = x\n",
    "dict_t = dict ()\n",
    "for i in l:\n",
    "    dict_t[i] = d[i]\n",
    "edges_sorted=dict_t\n",
    "\n",
    "\n",
    "l_lcc=list()\n",
    "for i in edges_sorted:\n",
    "    x=i\n",
    "    g_OH2.remove_edges_from([i])\n",
    "    l_lcc=list(nx.connected_components(g_OH2))\n",
    "    if (len(l_lcc)>1):\n",
    "        g_OH2.add_weighted_edges_from([(x[0],x[1],edges_sorted[(x[0],x[1])])])\n",
    "        continue\n",
    "l_edgesOH2=list(g_OH2.edges(data=True))\n",
    "print('l_edgesOH2=',list(g_OH2.edges(data=True)))\n",
    "\n",
    "l_edgesF=l_edgesOH2+edges_serrano\n",
    "\n",
    "l_edgesFinal=[]\n",
    "for e in l_edgesF:\n",
    "    l_edgesFinal.append((e[0],e[1],e[2]['weight']))\n",
    "\n",
    "print('l_edgesFinal: ',l_edgesF)\n",
    "g_VF=nx.Graph()\n",
    "g_VF.add_weighted_edges_from(l_edgesFinal)\n",
    "\n",
    "\n",
    "\n",
    "################ node_color= node:color ########################################\n",
    "node_color=dict()\n",
    "\n",
    "for i in g_VF:\n",
    "    n=node_community[i]\n",
    "    node_color[i]=partition_color[n[0]]\n",
    "\n",
    "list_colors=[]\n",
    "\n",
    "for i in g_VF:\n",
    "    if lo.count(i)==1:\n",
    "        list_colors.append('#F5F5F5')\n",
    "    else:\n",
    "        list_colors.append(node_color[i])\n",
    "\n",
    "\n",
    "\n",
    "############### Draw the figure of the global component ########################\n",
    "d=dict_degree\n",
    "\n",
    "#g1=g_inter\n",
    "d2=dict()\n",
    "for i in g_VF:\n",
    "    d2[i]=d[i]\n",
    "\n",
    "print('g_VF',g_VF.edges(data=True))\n",
    "plt.subplots_adjust(left = 0.01, bottom = 0.01, right = 0.99, top = 0.99)\n",
    "plt.figure(figsize=(w, h))  # image is 8 x 8 inches\n",
    "plt.axis('off')\n",
    "\n",
    "# edges\n",
    "all_weights = []\n",
    "for (node1,node2,data) in g_VF.edges(data=True):\n",
    "    #print('node1,node2,data: ',data)\n",
    "    all_weights.append(data['weight']) #we'll use this when determining edge thickness\n",
    "\n",
    "#4 b. Get unique weights\n",
    "unique_weights = list(set(all_weights))\n",
    "pos=nx.circular_layout(g_VF)\n",
    "#pos=nx.spring_layout(g1)\n",
    "#4 c. Plot the edges - one by one!\n",
    "node_list=g_VF.nodes()\n",
    "for weight in unique_weights:\n",
    "    weighted_edges = [(node1,node2) for (node1,node2,edge_attr) in g_VF.edges(data=True) if edge_attr['weight']==weight]\n",
    "    width = weight*len(node_list)*ep/sum(all_weights)\n",
    "    nx.draw_networkx_edges(g_VF,pos,edgelist=weighted_edges,width=width)\n",
    "a=len(node_list)*ep\n",
    "b=sum(all_weights)\n",
    "\n",
    "nx.draw_networkx(g_VF, pos, with_labels=True, node_size=[v * 80 for v in d2.values()] , node_color=list_colors, font_size=12, font_color='k', font_family='sans-serif', font_weight='bold')\n",
    "\n",
    "plt.savefig('3VF.png',dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b1c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9acd04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3.7.7-env]",
   "language": "python",
   "name": "conda-env-python3.7.7-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
